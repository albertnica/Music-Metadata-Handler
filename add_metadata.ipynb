{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933c2600",
   "metadata": {},
   "source": [
    "Configuration cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496bf847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# CONFIGURATION\n",
    "# -------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import logging\n",
    "import time\n",
    "import base64\n",
    "import json\n",
    "import re\n",
    "from typing import Optional, Tuple, List\n",
    "import requests\n",
    "from mutagen.flac import FLAC, Picture\n",
    "from mutagen.id3 import ID3, APIC, TIT2, TPE1, TALB, TDRC, TRCK, TPOS, TCON, TSRC, ID3NoHeaderError\n",
    "from mutagen.wave import WAVE\n",
    "import unicodedata\n",
    "from send2trash import send2trash\n",
    "import platform\n",
    "import struct\n",
    "import io\n",
    "import wave\n",
    "import tempfile\n",
    "\n",
    "# User-editable configuration\n",
    "CREDENTIALS_PATH = Path(\"credentials.json\")\n",
    "RECURSIVE = False   # True = aslo apply to files on subdirectories\n",
    "PROCESS_TOP_X = 100   # (int) number of files to process in this run\n",
    "\n",
    "# -------------------------\n",
    "# Filename parsing mode:\n",
    "# 0 = \"Artist - Title\"  (default, left=artist, right=title)\n",
    "# 1 = \"Title - Artist\"  (left=title, right=artist)\n",
    "# Applies to FLAC, MP3 and WAV filename fallback parsing.\n",
    "FILENAME_PARSE_MODE = 1\n",
    "# -------------------------\n",
    "\n",
    "# Spotify endpoints\n",
    "SPOTIFY_TOKEN_URL =          \"https://accounts.spotify.com/api/token\"\n",
    "SPOTIFY_SEARCH_URL =         \"https://api.spotify.com/v1/search\"\n",
    "SPOTIFY_ARTIST_URL =         \"https://api.spotify.com/v1/artists/{}\"\n",
    "SPOTIFY_ARTIST_ALBUMS_URL =  \"https://api.spotify.com/v1/artists/{}/albums\"\n",
    "SPOTIFY_ALBUM_TRACKS_URL =   \"https://api.spotify.com/v1/albums/{}/tracks\"\n",
    "\n",
    "# Timeouts and limits\n",
    "REQUEST_TIMEOUT = 12\n",
    "SPOTIFY_MAX_LIMIT = 50\n",
    "\n",
    "# Behavior flags\n",
    "OVERWRITE_TITLE_ARTIST_OR_ALBUM = 1   # 0 = preserve title/artist/album, 1 = overwrite\n",
    "UPDATE_ONLY_GENRE = 0                 # 1 = only update genre\n",
    "PRINT_SEARCH_INFO = 1                 # 1 = extended logs\n",
    "SEARCH_CANDIDATE_LIMIT = 5            # number of spotify tracks to search per music file\n",
    "MARKET: Optional[str] = None          # set e.g. \"US\" or \"ES\" to restrict results\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb1d20",
   "metadata": {},
   "source": [
    "Music utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1019f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# MUSIC UTILITIES SECTION\n",
    "# -------------------------\n",
    "_FILENAME_SPLIT_RE = re.compile(r\"\\s[-–—]\\s\")\n",
    "\n",
    "\n",
    "def infer_artist_title_from_filename(p: Path) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Infer artist and title from filename, respecting FILENAME_PARSE_MODE:\n",
    "      - If filename contains \"Left - Right\" (separator - or long dashes), return according to mode:\n",
    "          mode 0: (artist=Left, title=Right)\n",
    "          mode 1: (artist=Right, title=Left)\n",
    "      - If filename contains a single hyphen WITHOUT spaces, split on first hyphen and apply same mode.\n",
    "      - If filename has no separator, treat the entire stem as TITLE (artist unknown).\n",
    "    \"\"\"\n",
    "    stem = p.stem.strip()\n",
    "    if not stem:\n",
    "        return None, None\n",
    "\n",
    "    # Prefer explicit \" space - space \" separators\n",
    "    m = _FILENAME_SPLIT_RE.split(stem, maxsplit=1)\n",
    "    if len(m) == 2:\n",
    "        left = m[0].strip()\n",
    "        right = m[1].strip()\n",
    "        if FILENAME_PARSE_MODE == 0:\n",
    "            artist = left or None\n",
    "            title = right or None\n",
    "        else:\n",
    "            artist = right or None\n",
    "            title = left or None\n",
    "        return artist, title\n",
    "\n",
    "    # Fallback: a simple hyphen without spaces (e.g., \"Artist-Title\" or \"Title-Artist\")\n",
    "    if \"-\" in stem:\n",
    "        parts = stem.split(\"-\", 1)\n",
    "        left = parts[0].strip()\n",
    "        right = parts[1].strip()\n",
    "        if FILENAME_PARSE_MODE == 0:\n",
    "            artist = left or None\n",
    "            title = right or None\n",
    "        else:\n",
    "            artist = right or None\n",
    "            title = left or None\n",
    "        return artist, title\n",
    "\n",
    "    # NO separator: treat whole stem as title (artist unknown)\n",
    "    return None, stem or None\n",
    "\n",
    "\n",
    "def unique_temp_copy(src: Path) -> Path:\n",
    "    base_tmp = src.name + \".tmp\"\n",
    "    temp_path = src.with_name(base_tmp)\n",
    "    i = 0\n",
    "    while temp_path.exists():\n",
    "        i += 1\n",
    "        temp_path = src.with_name(f\"{src.name}.tmp{i}\")\n",
    "    shutil.copy2(str(src), str(temp_path))\n",
    "    return temp_path\n",
    "\n",
    "\n",
    "def send_original_to_trash(original: Path) -> None:\n",
    "    try:\n",
    "        send2trash(str(original))\n",
    "    except Exception:\n",
    "        try:\n",
    "            original.unlink()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237ae35",
   "metadata": {},
   "source": [
    "Search utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54cfd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# SEARCH UTILITIES SECTION\n",
    "# -------------------------\n",
    "def _strip_parentheses_with_feat(s: Optional[str]) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    def repl(m):\n",
    "        inner = m.group(1)\n",
    "        if re.search(r\"\\b(feat\\.?|ft\\.?)\\b\", inner, flags=re.IGNORECASE):\n",
    "            return \" \"\n",
    "        return m.group(0)\n",
    "    s = re.sub(r\"\\(([^)]*)\\)\", repl, s)\n",
    "    s = re.sub(r\"\\[([^]]*)\\]\", repl, s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def _extract_remixer_tokens_from_title(s: Optional[str]) -> List[str]:\n",
    "    if not s:\n",
    "        return []\n",
    "    res: List[str] = []\n",
    "    for m in re.finditer(r\"\\(([^)]*remix[^)]*)\\)\", s, flags=re.IGNORECASE):\n",
    "        inner = m.group(1)\n",
    "        name = re.sub(r\"\\bremix\\b\", \" \", inner, flags=re.IGNORECASE)\n",
    "        name = re.sub(r\"[^0-9a-zA-Z\\s]\", \" \", name)\n",
    "        name = unicodedata.normalize(\"NFKD\", name)\n",
    "        name = \"\".join(ch for ch in name if not unicodedata.combining(ch))\n",
    "        name = re.sub(r\"\\s+\", \" \", name).strip().lower()\n",
    "        if name:\n",
    "            res.extend([t for t in name.split() if t])\n",
    "    for m in re.finditer(r\"\\[([^]]*remix[^]]*)\\]\", s, flags=re.IGNORECASE):\n",
    "        inner = m.group(1)\n",
    "        name = re.sub(r\"\\bremix\\b\", \" \", inner, flags=re.IGNORECASE)\n",
    "        name = re.sub(r\"[^0-9a-zA-Z\\s]\", \" \", name)\n",
    "        name = unicodedata.normalize(\"NFKD\", name)\n",
    "        name = \"\".join(ch for ch in name if not unicodedata.combining(ch))\n",
    "        name = re.sub(r\"\\s+\", \" \", name).strip().lower()\n",
    "        if name:\n",
    "            res.extend([t for t in name.split() if t])\n",
    "    return res\n",
    "\n",
    "\n",
    "def _normalize_text_basic(s: Optional[str]) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = re.sub(r\"[()]+\", \" \", s)\n",
    "    s = re.sub(r\"\\b(feat\\.?|ft\\.?)\\b\", \" \", s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r\"[^0-9a-zA-Z\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip().lower()\n",
    "    return s\n",
    "\n",
    "\n",
    "def _normalize_artist_for_search(s: Optional[str]) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s2 = s.replace(\",\", \" \").replace(\"\\\\\", \" \").replace(\"/\", \" \")\n",
    "    s2 = _strip_parentheses_with_feat(s2)\n",
    "    return _normalize_text_basic(s2)\n",
    "\n",
    "\n",
    "def _normalize_title_for_search(s: Optional[str]) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s2 = _strip_parentheses_with_feat(s)\n",
    "    return _normalize_text_basic(s2)\n",
    "\n",
    "\n",
    "def _tokens(n: str) -> List[str]:\n",
    "    if not n:\n",
    "        return []\n",
    "    return [t for t in n.split() if t]\n",
    "\n",
    "\n",
    "def _tokens_in_candidate(tokens: List[str], candidate_norm: str) -> bool:\n",
    "    if not tokens:\n",
    "        return True\n",
    "    cand_set = set(candidate_norm.split())\n",
    "    return all(tok in cand_set for tok in tokens)\n",
    "\n",
    "\n",
    "def _build_sanitized_query(n_artist: str, n_title: str, n_album: str, fielded: bool = True) -> str:\n",
    "    def quote_and_escape(s: str) -> str:\n",
    "        s2 = s.replace('\"', ' ')\n",
    "        s2 = re.sub(r'\\s+', ' ', s2).strip()\n",
    "        return f'\"{s2}\"' if s2 else ''\n",
    "    if fielded and (n_artist or n_title or n_album):\n",
    "        parts = []\n",
    "        if n_title:\n",
    "            parts.append(f'track:{quote_and_escape(n_title)}')\n",
    "        if n_artist:\n",
    "            parts.append(f'artist:{quote_and_escape(n_artist)}')\n",
    "        if n_album:\n",
    "            parts.append(f'album:{quote_and_escape(n_album)}')\n",
    "        return \" \".join([p for p in parts if p])\n",
    "    parts = []\n",
    "    if n_artist:\n",
    "        parts.append(n_artist)\n",
    "    if n_title:\n",
    "        parts.append(n_title)\n",
    "    if n_album:\n",
    "        parts.append(n_album)\n",
    "    return \" \".join(parts) if parts else '\"\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e990725",
   "metadata": {},
   "source": [
    "Search section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9ceadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# SPOTIFY CLIENT / SEARCH SECTION\n",
    "# -------------------------\n",
    "def get_spotify_token(client_id: str, client_secret: str, ttl_margin: int = 5) -> Tuple[str, int]:\n",
    "    auth = base64.b64encode(f\"{client_id}:{client_secret}\".encode(\"utf-8\")).decode(\"ascii\")\n",
    "    headers = {\"Authorization\": f\"Basic {auth}\"}\n",
    "    data = {\"grant_type\": \"client_credentials\"}\n",
    "    resp = requests.post(SPOTIFY_TOKEN_URL, headers=headers, data=data, timeout=REQUEST_TIMEOUT)\n",
    "    resp.raise_for_status()\n",
    "    j = resp.json()\n",
    "    token = j[\"access_token\"]\n",
    "    expires_in = int(j.get(\"expires_in\", 3600))\n",
    "    expires_at = int(time.time()) + expires_in - ttl_margin\n",
    "    return token, expires_at\n",
    "\n",
    "\n",
    "def spotifysearch(token: str, q: str, type_: str = \"track\", limit: int = 20, offset: int = 0, market: Optional[str] = None) -> Optional[dict]:\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    params = {\"q\": q, \"type\": type_, \"limit\": limit, \"offset\": offset}\n",
    "    if market:\n",
    "        params[\"market\"] = market\n",
    "    try:\n",
    "        r = requests.get(SPOTIFY_SEARCH_URL, headers=headers, params=params, timeout=REQUEST_TIMEOUT)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if r.status_code == 401 or not r.ok:\n",
    "        return None\n",
    "    try:\n",
    "        return r.json()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def spotify_get_artist_albums(token: str, artist_id: str, limit: int = SPOTIFY_MAX_LIMIT, offset: int = 0, market: Optional[str] = None) -> Optional[dict]:\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if market:\n",
    "        params[\"market\"] = market\n",
    "    try:\n",
    "        r = requests.get(SPOTIFY_ARTIST_ALBUMS_URL.format(artist_id), headers=headers, params=params, timeout=REQUEST_TIMEOUT)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if not r.ok:\n",
    "        return None\n",
    "    try:\n",
    "        return r.json()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def spotify_get_album_tracks(token: str, album_id: str, limit: int = SPOTIFY_MAX_LIMIT, offset: int = 0, market: Optional[str] = None) -> Optional[dict]:\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    params = {\"limit\": limit, \"offset\": offset}\n",
    "    if market:\n",
    "        params[\"market\"] = market\n",
    "    try:\n",
    "        r = requests.get(SPOTIFY_ALBUM_TRACKS_URL.format(album_id), headers=headers, params=params, timeout=REQUEST_TIMEOUT)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if not r.ok:\n",
    "        return None\n",
    "    try:\n",
    "        return r.json()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def spotify_find_best_match(token: str, artist: Optional[str], album: Optional[str], title: Optional[str],\n",
    "                            combined_limit: int = None) -> Optional[dict]:\n",
    "    if combined_limit is None:\n",
    "        combined_limit = SEARCH_CANDIDATE_LIMIT\n",
    "\n",
    "    n_artist = _normalize_artist_for_search(artist) if artist else \"\"\n",
    "    n_title = _normalize_title_for_search(title) if title else \"\"\n",
    "    n_album = _normalize_title_for_search(album) if album else \"\"\n",
    "\n",
    "    artist_tokens = _tokens(n_artist)\n",
    "    title_tokens = _tokens(n_title)\n",
    "    album_tokens = _tokens(n_album)\n",
    "    remixer_tokens = _extract_remixer_tokens_from_title(title or \"\")\n",
    "\n",
    "    if PRINT_SEARCH_INFO:\n",
    "        logging.info(\"Sanitized search input: artist='%s' | title='%s' | album='%s'\", n_artist, n_title, n_album)\n",
    "\n",
    "    # Build queries: fielded first, then plain\n",
    "    queries: List[Tuple[str, str]] = []\n",
    "    primary_q_fielded = _build_sanitized_query(n_artist, n_title, n_album, fielded=True)\n",
    "    if primary_q_fielded:\n",
    "        queries.append((\"track\", primary_q_fielded))\n",
    "    at_q_fielded = _build_sanitized_query(n_artist, n_title, \"\", fielded=True)\n",
    "    if at_q_fielded and at_q_fielded != primary_q_fielded:\n",
    "        queries.append((\"track\", at_q_fielded))\n",
    "    aa_q_fielded = _build_sanitized_query(n_artist, \"\", n_album, fielded=True)\n",
    "    if aa_q_fielded and aa_q_fielded not in (primary_q_fielded, at_q_fielded):\n",
    "        queries.append((\"album\", aa_q_fielded))\n",
    "    t_q_fielded = _build_sanitized_query(\"\", n_title, \"\", fielded=True)\n",
    "    if t_q_fielded and t_q_fielded not in (primary_q_fielded, at_q_fielded, aa_q_fielded):\n",
    "        queries.append((\"track\", t_q_fielded))\n",
    "    a_q_fielded = _build_sanitized_query(\"\", \"\", n_album, fielded=True)\n",
    "    if a_q_fielded and a_q_fielded not in (primary_q_fielded, at_q_fielded, aa_q_fielded, t_q_fielded):\n",
    "        queries.append((\"album\", a_q_fielded))\n",
    "\n",
    "    primary_q_plain = _build_sanitized_query(n_artist, n_title, n_album, fielded=False)\n",
    "    if primary_q_plain and primary_q_plain not in (q for _, q in queries):\n",
    "        queries.append((\"track\", primary_q_plain))\n",
    "\n",
    "    seen_keys = set()\n",
    "    overall_idx = 0\n",
    "\n",
    "    for (kind, q) in queries:\n",
    "        if PRINT_SEARCH_INFO:\n",
    "            logging.info(\"Query base: '%s' | type=%s | target=%d\", q, kind, combined_limit)\n",
    "        offset = 0\n",
    "        while True:\n",
    "            per_request = min(SPOTIFY_MAX_LIMIT, combined_limit - overall_idx)\n",
    "            if per_request <= 0:\n",
    "                break\n",
    "            if PRINT_SEARCH_INFO:\n",
    "                logging.info(\"Searching Spotify: q='%s' type=%s limit=%d offset=%d market=%s\", q, kind, per_request, offset, MARKET)\n",
    "            j = spotifysearch(token, q, type_=kind, limit=per_request, offset=offset, market=MARKET)\n",
    "            if not j:\n",
    "                break\n",
    "            items = j.get((kind + \"s\") if kind in (\"album\", \"track\") else \"tracks\", {}).get(\"items\", [])\n",
    "            if not isinstance(items, list) or not items:\n",
    "                break\n",
    "            for it in items:\n",
    "                it_id = it.get(\"id\")\n",
    "                if it_id:\n",
    "                    key = f\"id:{it_id}\"\n",
    "                else:\n",
    "                    cand_title = _normalize_text_basic(it.get(\"name\"))\n",
    "                    cand_artists = \" \".join(a.get(\"name\", \"\") for a in it.get(\"artists\", []))\n",
    "                    cand_artist_norm = _normalize_artist_for_search(cand_artists)\n",
    "                    album_info = (it.get(\"album\") or {}) if kind == \"track\" else it\n",
    "                    cand_album_name = _normalize_title_for_search((album_info.get(\"name\") or \"\"))\n",
    "                    key = f\"key:{cand_title}|{cand_artist_norm}|{cand_album_name}\"\n",
    "                if key in seen_keys:\n",
    "                    continue\n",
    "                overall_idx += 1\n",
    "                seen_keys.add(key)\n",
    "                if kind == \"track\":\n",
    "                    cand_title = _normalize_text_basic(it.get(\"name\"))\n",
    "                    cand_artists = \" \".join(a.get(\"name\", \"\") for a in it.get(\"artists\", []))\n",
    "                    cand_artist_norm = _normalize_artist_for_search(cand_artists)\n",
    "                    album_info = it.get(\"album\", {}) or {}\n",
    "                    cand_album_name = _normalize_title_for_search(album_info.get(\"name\"))\n",
    "                else:\n",
    "                    cand_title = _normalize_text_basic(it.get(\"name\"))\n",
    "                    cand_artist_norm = _normalize_text_basic(\" \".join(a.get(\"name\", \"\") for a in it.get(\"artists\", [])))\n",
    "                    cand_album_name = cand_title\n",
    "                if PRINT_SEARCH_INFO:\n",
    "                    logging.info(\"Candidate #%d: title='%s' | artist='%s' | album='%s'\", overall_idx, cand_title, cand_artist_norm, cand_album_name)\n",
    "                title_ok = _tokens_in_candidate(title_tokens, cand_title)\n",
    "                artist_ok = (not artist_tokens) or _tokens_in_candidate(artist_tokens, cand_artist_norm) or (remixer_tokens and _tokens_in_candidate(remixer_tokens, cand_artist_norm))\n",
    "                album_ok = True\n",
    "                if album_tokens:\n",
    "                    album_ok = _tokens_in_candidate(album_tokens, cand_album_name)\n",
    "                accepted = bool(title_ok and artist_ok and album_ok)\n",
    "                if PRINT_SEARCH_INFO:\n",
    "                    logging.info(\"ACCEPTED\" if accepted else \"REJECTED\")\n",
    "                if accepted:\n",
    "                    return it\n",
    "                if overall_idx >= combined_limit:\n",
    "                    break\n",
    "            if overall_idx >= combined_limit:\n",
    "                break\n",
    "            offset += per_request\n",
    "            if len(items) < per_request:\n",
    "                break\n",
    "        if overall_idx >= combined_limit:\n",
    "            break\n",
    "\n",
    "    # Fallback: artist->albums->tracks exploration\n",
    "    if n_artist:\n",
    "        artist_search_q = f'artist:\"{n_artist}\"'\n",
    "        if PRINT_SEARCH_INFO:\n",
    "            logging.info(\"Fallback artist search: %s\", artist_search_q)\n",
    "        artist_resp = spotifysearch(token, artist_search_q, type_=\"artist\", limit=1, offset=0, market=MARKET)\n",
    "        artist_items = []\n",
    "        try:\n",
    "            artist_items = artist_resp.get(\"artists\", {}).get(\"items\", []) if artist_resp else []\n",
    "        except Exception:\n",
    "            artist_items = []\n",
    "        if artist_items:\n",
    "            artist_id = artist_items[0].get(\"id\")\n",
    "            if PRINT_SEARCH_INFO:\n",
    "                logging.info(\"Found artist id=%s; enumerating albums\", artist_id)\n",
    "            if artist_id:\n",
    "                a_off = 0\n",
    "                while True:\n",
    "                    a_resp = spotify_get_artist_albums(token, artist_id, limit=SPOTIFY_MAX_LIMIT, offset=a_off, market=MARKET)\n",
    "                    if not a_resp:\n",
    "                        break\n",
    "                    albums = a_resp.get(\"items\", []) or []\n",
    "                    if not albums:\n",
    "                        break\n",
    "                    for alb in albums:\n",
    "                        alb_id = alb.get(\"id\")\n",
    "                        if not alb_id:\n",
    "                            continue\n",
    "                        t_off = 0\n",
    "                        while True:\n",
    "                            t_resp = spotify_get_album_tracks(token, alb_id, limit=SPOTIFY_MAX_LIMIT, offset=t_off, market=MARKET)\n",
    "                            if not t_resp:\n",
    "                                break\n",
    "                            tracks = t_resp.get(\"items\", []) or []\n",
    "                            if not tracks:\n",
    "                                break\n",
    "                            for tr in tracks:\n",
    "                                tr_id = tr.get(\"id\")\n",
    "                                if tr_id and f\"id:{tr_id}\" in seen_keys:\n",
    "                                    continue\n",
    "                                it_like = {\"id\": tr.get(\"id\"), \"name\": tr.get(\"name\"), \"artists\": tr.get(\"artists\", []), \"album\": {\"name\": alb.get(\"name\")}}\n",
    "                                cand_title = _normalize_text_basic(it_like.get(\"name\"))\n",
    "                                cand_artists = \" \".join(a.get(\"name\", \"\") for a in it_like.get(\"artists\", []))\n",
    "                                cand_artist_norm = _normalize_artist_for_search(cand_artists)\n",
    "                                cand_album_name = _normalize_title_for_search(alb.get(\"name\"))\n",
    "                                title_ok = _tokens_in_candidate(title_tokens, cand_title)\n",
    "                                artist_ok = (not artist_tokens) or _tokens_in_candidate(artist_tokens, cand_artist_norm) or (remixer_tokens and _tokens_in_candidate(remixer_tokens, cand_artist_norm))\n",
    "                                album_ok = True\n",
    "                                if album_tokens:\n",
    "                                    album_ok = _tokens_in_candidate(album_tokens, cand_album_name)\n",
    "                                if title_ok and artist_ok and album_ok:\n",
    "                                    return it_like\n",
    "                                seen_keys.add(f\"id:{tr_id}\" if tr_id else f\"key:{cand_title}|{cand_artist_norm}|{cand_album_name}\")\n",
    "                            if len(tracks) < SPOTIFY_MAX_LIMIT:\n",
    "                                break\n",
    "                            t_off += SPOTIFY_MAX_LIMIT\n",
    "                    if len(albums) < SPOTIFY_MAX_LIMIT:\n",
    "                        break\n",
    "                    a_off += SPOTIFY_MAX_LIMIT\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201d50f",
   "metadata": {},
   "source": [
    "Tag writting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd22ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# TAG WRITING / FORMAT-SPECIFIC HANDLERS\n",
    "# -------------------------\n",
    "def download_image_bytes(url: str) -> Optional[Tuple[bytes, str]]:\n",
    "    try:\n",
    "        r = requests.get(url, timeout=REQUEST_TIMEOUT)\n",
    "        r.raise_for_status()\n",
    "        mime = r.headers.get(\"Content-Type\", \"\") or \"image/jpeg\"\n",
    "        return r.content, mime\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_artist_genres(token: str, artist_id: str) -> List[str]:\n",
    "    try:\n",
    "        headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "        r = requests.get(SPOTIFY_ARTIST_URL.format(artist_id), headers=headers, timeout=REQUEST_TIMEOUT)\n",
    "        if r.ok:\n",
    "            j = r.json()\n",
    "            genres = j.get(\"genres\", [])\n",
    "            if isinstance(genres, list):\n",
    "                return genres\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "\n",
    "def remove_existing_pictures_generic(path: Path, audio_obj) -> None:\n",
    "    ext = path.suffix.lower()\n",
    "    try:\n",
    "        if isinstance(audio_obj, ID3):\n",
    "            try:\n",
    "                audio_obj.delall(\"APIC\")\n",
    "            except Exception:\n",
    "                pass\n",
    "            return\n",
    "        if ext == \".flac\":\n",
    "            if hasattr(audio_obj, \"clear_pictures\"):\n",
    "                try:\n",
    "                    audio_obj.clear_pictures()\n",
    "                    return\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if hasattr(audio_obj, \"pictures\"):\n",
    "                try:\n",
    "                    audio_obj.pictures[:] = []\n",
    "                    return\n",
    "                except Exception:\n",
    "                    pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def set_genre_on_audio(path: Path, audio_tmp, genres_list: List[str]) -> None:\n",
    "    ext = path.suffix.lower()\n",
    "    genre_value = \"; \".join(genres_list) if genres_list else None\n",
    "    try:\n",
    "        if isinstance(audio_tmp, ID3):\n",
    "            if genre_value:\n",
    "                try:\n",
    "                    audio_tmp.delall(\"TCON\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "                audio_tmp.add(TCON(encoding=3, text=genre_value))\n",
    "            else:\n",
    "                try:\n",
    "                    audio_tmp.delall(\"TCON\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "            return\n",
    "        if ext == \".flac\":\n",
    "            if audio_tmp.tags is None:\n",
    "                audio_tmp.tags = {}\n",
    "            if genre_value:\n",
    "                audio_tmp.tags[\"genre\"] = [genre_value]\n",
    "            else:\n",
    "                for k in (\"genre\", \"genres\"):\n",
    "                    if k in audio_tmp.tags:\n",
    "                        del audio_tmp.tags[k]\n",
    "            return\n",
    "        if ext == \".wav\":\n",
    "            if getattr(audio_tmp, \"tags\", None) is None:\n",
    "                audio_tmp.tags = {}\n",
    "            keys_to_try = [\"IGNR\", \"IGEN\", \"GENR\", \"GENRE\"]\n",
    "            if genre_value:\n",
    "                for k in keys_to_try:\n",
    "                    try:\n",
    "                        audio_tmp.tags[k] = [genre_value]\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            else:\n",
    "                for k in keys_to_try:\n",
    "                    try:\n",
    "                        if k in audio_tmp.tags:\n",
    "                            del audio_tmp.tags[k]\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            return\n",
    "        if hasattr(audio_tmp, \"tags\"):\n",
    "            if audio_tmp.tags is None:\n",
    "                audio_tmp.tags = {}\n",
    "            if genre_value:\n",
    "                audio_tmp.tags[\"genre\"] = [genre_value]\n",
    "            else:\n",
    "                try:\n",
    "                    if \"genre\" in audio_tmp.tags:\n",
    "                        del audio_tmp.tags[\"genre\"]\n",
    "                except Exception:\n",
    "                    pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "# Helpers to build RIFF LIST/INFO and ID3 bytes\n",
    "def _encode_text_for_info(s: str) -> bytes:\n",
    "    b = s.encode(\"utf-8\")\n",
    "    if len(b) % 2 == 1:\n",
    "        b += b'\\x00'\n",
    "    return b\n",
    "\n",
    "\n",
    "def build_info_list_chunk(metadata: dict) -> bytes:\n",
    "    subchunks = b\"\"\n",
    "    mapping = [\n",
    "        (\"INAM\", \"title\"),\n",
    "        (\"IART\", \"artist\"),\n",
    "        (\"IPRD\", \"album\"),\n",
    "        (\"ICRD\", \"date\"),\n",
    "        (\"ITRK\", \"track\"),\n",
    "        (\"TPOS\", \"disc\"),\n",
    "        (\"IGNR\", \"genre\"),\n",
    "    ]\n",
    "    for cid, key in mapping:\n",
    "        v = metadata.get(key)\n",
    "        if v:\n",
    "            data = _encode_text_for_info(str(v))\n",
    "            subchunks += cid.encode('ascii') + struct.pack('<I', len(data)) + data\n",
    "    if not subchunks:\n",
    "        return b\"\"\n",
    "    size = 4 + len(subchunks)  # \"INFO\" + subchunks\n",
    "    chunk = b\"LIST\" + struct.pack('<I', size) + b\"INFO\" + subchunks\n",
    "    return chunk\n",
    "\n",
    "\n",
    "def build_id3_bytes_for_wav(image_bytes: Optional[bytes], mime: Optional[str], metadata: dict) -> bytes:\n",
    "    \"\"\"\n",
    "    Build an ID3v2.3 tag in memory including APIC and textual frames:\n",
    "    TIT2, TPE1, TALB, TDRC, TRCK, TPOS, TCON, TSRC (if provided).\n",
    "    Use encoding=1 (UTF-16) for textual frames for better WAV+Mp3tag compatibility.\n",
    "    \"\"\"\n",
    "    id3 = ID3()\n",
    "    try:\n",
    "        if image_bytes:\n",
    "            id3.add(APIC(encoding=3, mime=mime or \"image/jpeg\", type=3, desc=\"Cover\", data=image_bytes))\n",
    "        # textual frames in UTF-16\n",
    "        if metadata.get(\"title\"):\n",
    "            id3.add(TIT2(encoding=1, text=str(metadata[\"title\"])))\n",
    "        if metadata.get(\"artist\"):\n",
    "            id3.add(TPE1(encoding=1, text=str(metadata[\"artist\"])))\n",
    "        if metadata.get(\"album\"):\n",
    "            id3.add(TALB(encoding=1, text=str(metadata[\"album\"])))\n",
    "        if metadata.get(\"date\"):\n",
    "            id3.add(TDRC(encoding=1, text=str(metadata[\"date\"])))\n",
    "        if metadata.get(\"track\"):\n",
    "            id3.add(TRCK(encoding=1, text=str(metadata[\"track\"])))\n",
    "        if metadata.get(\"disc\"):\n",
    "            id3.add(TPOS(encoding=1, text=str(metadata[\"disc\"])))\n",
    "        if metadata.get(\"genre\"):\n",
    "            id3.add(TCON(encoding=1, text=str(metadata[\"genre\"])))\n",
    "        if metadata.get(\"isrc\"):\n",
    "            try:\n",
    "                id3.add(TSRC(encoding=1, text=str(metadata[\"isrc\"])))\n",
    "            except Exception:\n",
    "                pass\n",
    "        bio = io.BytesIO()\n",
    "        id3.save(bio, v2_version=3)\n",
    "        b = bio.getvalue()\n",
    "        if len(b) % 2 == 1:\n",
    "            b += b'\\x00'\n",
    "        return b\n",
    "    except Exception:\n",
    "        return b\"\"\n",
    "\n",
    "\n",
    "# RIFF helpers\n",
    "def find_first_riff_offset(b: bytes) -> int:\n",
    "    return b.find(b\"RIFF\")\n",
    "\n",
    "\n",
    "def parse_riff_chunks_and_find_data_offset(b: bytes, start_offset: int = 0):\n",
    "    if len(b) < start_offset + 12:\n",
    "        return -1, None, start_offset + 4\n",
    "    if b[start_offset:start_offset+4] != b\"RIFF\":\n",
    "        return -1, None, start_offset + 4\n",
    "    off = start_offset + 12\n",
    "    end = len(b)\n",
    "    while off + 8 <= end:\n",
    "        cid = b[off:off+4]\n",
    "        sz = struct.unpack_from('<I', b, off+4)[0]\n",
    "        if cid == b\"data\":\n",
    "            return off, sz, start_offset + 4\n",
    "        advance = 8 + sz + (sz % 2)\n",
    "        off += advance\n",
    "    return -1, None, start_offset + 4\n",
    "\n",
    "\n",
    "def insert_chunk_before_data(original_bytes: bytes, chunk_id: bytes, chunk_data: bytes) -> bytes:\n",
    "    riff_off = find_first_riff_offset(original_bytes)\n",
    "    if riff_off == -1:\n",
    "        raise RuntimeError(\"RIFF header not found in file\")\n",
    "    data_off, data_sz, riff_size_field = parse_riff_chunks_and_find_data_offset(original_bytes, riff_off)\n",
    "    add_len = 8 + len(chunk_data)\n",
    "    orig_riff_size = struct.unpack_from('<I', original_bytes, riff_off+4)[0]\n",
    "    new_riff_size = orig_riff_size + add_len\n",
    "    new_bytes = bytearray(original_bytes)\n",
    "    struct.pack_into('<I', new_bytes, riff_off+4, new_riff_size)\n",
    "    chunk = bytearray()\n",
    "    chunk += chunk_id\n",
    "    chunk += struct.pack('<I', len(chunk_data))\n",
    "    chunk += chunk_data\n",
    "    if data_off == -1:\n",
    "        new_bytes.extend(chunk)\n",
    "        return bytes(new_bytes)\n",
    "    else:\n",
    "        new = new_bytes[:data_off] + chunk + new_bytes[data_off:]\n",
    "        return bytes(new)\n",
    "\n",
    "\n",
    "def strip_id3_and_list_info(orig_bytes: bytes) -> bytes:\n",
    "    \"\"\"\n",
    "    Remove any existing 'id3 ' chunks and 'LIST' chunks whose subtype is 'INFO'\n",
    "    from a RIFF/WAVE byte buffer. Rebuilds RIFF size field accordingly.\n",
    "    Returns bytes (unchanged if nothing to remove).\n",
    "    \"\"\"\n",
    "    riff_off = find_first_riff_offset(orig_bytes)\n",
    "    if riff_off == -1:\n",
    "        return orig_bytes\n",
    "    if len(orig_bytes) < riff_off + 12:\n",
    "        return orig_bytes\n",
    "\n",
    "    off = riff_off + 12\n",
    "    end = len(orig_bytes)\n",
    "    kept_chunks = bytearray()\n",
    "    while off + 8 <= end:\n",
    "        cid = orig_bytes[off:off+4]\n",
    "        sz = struct.unpack_from('<I', orig_bytes, off+4)[0]\n",
    "        data_start = off + 8\n",
    "        data_end = data_start + sz\n",
    "        if data_end > end:\n",
    "            # malformed - keep rest and break\n",
    "            kept_chunks += orig_bytes[off:end]\n",
    "            break\n",
    "        skip = False\n",
    "        if cid == b\"id3 \":\n",
    "            skip = True\n",
    "        elif cid == b\"LIST\":\n",
    "            # check subtype (first 4 bytes inside LIST data)\n",
    "            if orig_bytes[data_start:data_start+4] == b\"INFO\":\n",
    "                skip = True\n",
    "        if not skip:\n",
    "            # include chunk + padding byte if present\n",
    "            chunk_end = data_end + (sz % 2)\n",
    "            kept_chunks += orig_bytes[off:chunk_end]\n",
    "        off = data_end + (sz % 2)\n",
    "\n",
    "    new_riff_size = 4 + len(kept_chunks)  # 'WAVE' (4) + kept chunks\n",
    "    new_buf = bytearray()\n",
    "    new_buf += b\"RIFF\"\n",
    "    new_buf += struct.pack('<I', new_riff_size)\n",
    "    new_buf += orig_bytes[riff_off+8:riff_off+12]  # 'WAVE' (4 bytes) - keep original WAVE id\n",
    "    new_buf += kept_chunks\n",
    "    return bytes(new_buf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22acb7e1",
   "metadata": {},
   "source": [
    "CORE (update metadata for a single file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29727454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# CORE: update metadata for a single file (handles FLAC/MP3/WAV)\n",
    "# -------------------------\n",
    "def overwrite_metadata_with_spotify(file_path: Path, token: str) -> bool:\n",
    "    \"\"\"\n",
    "    Core update function:\n",
    "    - Read tags (FLAC/ID3/WAVE)\n",
    "    - Determine artist/title/album (and fallback to filename)\n",
    "    - Search Spotify (ISRC first then containment)\n",
    "    - Create temp copy, write tags:\n",
    "        * FLAC: standard mutagen tags + pictures (remove previous pictures first)\n",
    "        * MP3: ID3 frames + APIC (remove previous APIC first)\n",
    "        * WAV: create clean WAV candidate, write LIST/INFO and insert 'id3 ' chunk with ID3v2.3(APIC + textual frames UTF-16)\n",
    "               (strip pre-existing id3/LIST INFO chunks to avoid duplicates)\n",
    "    - Replace original with modified temp (original -> trash)\n",
    "    \"\"\"\n",
    "    ext = file_path.suffix.lower()\n",
    "    wav_has_id3 = False\n",
    "    audio = None\n",
    "    try:\n",
    "        if ext == \".flac\":\n",
    "            audio = FLAC(str(file_path))\n",
    "        elif ext == \".mp3\":\n",
    "            try:\n",
    "                audio = ID3(str(file_path))\n",
    "            except ID3NoHeaderError:\n",
    "                audio = ID3()\n",
    "        elif ext == \".wav\":\n",
    "            # Prefer ID3 chunk inside WAV if present (mutagen will detect)\n",
    "            try:\n",
    "                audio = ID3(str(file_path))\n",
    "                wav_has_id3 = True\n",
    "            except ID3NoHeaderError:\n",
    "                try:\n",
    "                    audio = WAVE(str(file_path))\n",
    "                    wav_has_id3 = False\n",
    "                except Exception:\n",
    "                    audio = None\n",
    "                    wav_has_id3 = False\n",
    "        else:\n",
    "            logging.info(\"Unsupported format: %s\", file_path.name)\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        logging.error(\"Could not open %s: %s\", file_path.name, e)\n",
    "        return False\n",
    "\n",
    "    # collect tags generically\n",
    "    tags = None\n",
    "    try:\n",
    "        if isinstance(audio, FLAC):\n",
    "            tags = audio.tags or {}\n",
    "        elif isinstance(audio, ID3):\n",
    "            tags = audio\n",
    "        elif isinstance(audio, WAVE):\n",
    "            tags = getattr(audio, \"tags\", {}) or {}\n",
    "        else:\n",
    "            tags = {}\n",
    "    except Exception:\n",
    "        tags = {}\n",
    "\n",
    "    def _val_to_str(v):\n",
    "        try:\n",
    "            if v is None:\n",
    "                return None\n",
    "            if isinstance(v, (list, tuple)) and v:\n",
    "                v0 = v[0]\n",
    "                if hasattr(v0, \"text\"):\n",
    "                    txt = getattr(v0, \"text\")\n",
    "                    if isinstance(txt, (list, tuple)):\n",
    "                        return str(txt[0])\n",
    "                    return str(txt)\n",
    "                return str(v0)\n",
    "            if hasattr(v, \"text\"):\n",
    "                txt = getattr(v, \"text\")\n",
    "                if isinstance(txt, (list, tuple)):\n",
    "                    return str(txt[0])\n",
    "                return str(txt)\n",
    "            return str(v)\n",
    "        except Exception:\n",
    "            try:\n",
    "                return str(v)\n",
    "            except Exception:\n",
    "                return None\n",
    "\n",
    "    def first_tag_generic(k):\n",
    "        try:\n",
    "            if isinstance(audio, FLAC):\n",
    "                v = tags.get(k)\n",
    "                if v:\n",
    "                    if isinstance(v, (list, tuple)):\n",
    "                        return str(v[0])\n",
    "                    return str(v)\n",
    "                return None\n",
    "            if isinstance(audio, ID3):\n",
    "                map_frames = {\"artist\":\"TPE1\",\"albumartist\":\"TPE2\",\"album\":\"TALB\",\"title\":\"TIT2\",\"date\":\"TDRC\",\"tracknumber\":\"TRCK\",\"discnumber\":\"TPOS\",\"isrc\":\"TSRC\",\"genre\":\"TCON\"}\n",
    "                frame = map_frames.get(k)\n",
    "                if frame and frame in tags:\n",
    "                    f = tags.getall(frame)\n",
    "                    if f:\n",
    "                        try:\n",
    "                            txt = f[0].text\n",
    "                            if isinstance(txt,(list,tuple)):\n",
    "                                return str(txt[0])\n",
    "                            return str(txt)\n",
    "                        except Exception:\n",
    "                            try:\n",
    "                                return str(f[0])\n",
    "                            except Exception:\n",
    "                                return None\n",
    "                return None\n",
    "            # WAVE / RIFF INFO fallback (and ID3-like frames stored in WAVE.tags)\n",
    "            if getattr(tags, \"get\", None):\n",
    "                v = tags.get(k)\n",
    "                if v:\n",
    "                    return _val_to_str(v)\n",
    "                alt_keys = {\n",
    "                    \"title\":[\"INAM\",\"NAME\",\"TITLE\",\"TIT2\"],\n",
    "                    \"artist\":[\"IART\",\"AUTH\",\"ARTIST\",\"TPE1\"],\n",
    "                    \"album\":[\"IPRD\",\"ALBUM\",\"TALB\"],\n",
    "                    \"date\":[\"ICRD\",\"DATE\",\"YEAR\",\"TDRC\"],\n",
    "                    \"tracknumber\":[\"ITRK\",\"TRACKNUMBER\",\"TRCK\"],\n",
    "                    \"discnumber\":[\"TPOS\",\"DISCNUMBER\"],\n",
    "                    \"isrc\":[\"TSRC\",\"ISRC\"],\n",
    "                    \"genre\":[\"IGEN\",\"IGNR\",\"GENR\",\"GENRE\",\"TCON\"]\n",
    "                }\n",
    "                for alt in alt_keys.get(k, []):\n",
    "                    try:\n",
    "                        vv = tags.get(alt)\n",
    "                        if vv:\n",
    "                            return _val_to_str(vv)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "            return None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    artist = first_tag_generic(\"artist\") or first_tag_generic(\"albumartist\")\n",
    "    album = first_tag_generic(\"album\")\n",
    "    title = first_tag_generic(\"title\")\n",
    "    isrc_tag = first_tag_generic(\"isrc\") or first_tag_generic(\"ISRC\")\n",
    "\n",
    "    # filename fallback\n",
    "    ai, ti = infer_artist_title_from_filename(file_path)\n",
    "    artist = artist or ai\n",
    "    title = title or ti\n",
    "\n",
    "    if not artist and not title:\n",
    "        logging.info(\"Insufficient metadata for: %s\", file_path.name)\n",
    "        return False\n",
    "\n",
    "    if PRINT_SEARCH_INFO:\n",
    "        if artist and title:\n",
    "            logging.info(\"Searching with artist+title (both available).\")\n",
    "        elif title and not artist:\n",
    "            logging.info(\"Searching with title only.\")\n",
    "        elif artist and not title:\n",
    "            logging.info(\"Searching with artist only.\")\n",
    "\n",
    "    artist_for_search = _strip_parentheses_with_feat(artist) if artist else None\n",
    "    title_for_search = _strip_parentheses_with_feat(title) if title else None\n",
    "    album_for_search = _strip_parentheses_with_feat(album) if album else None\n",
    "\n",
    "    if PRINT_SEARCH_INFO:\n",
    "        sanitized_artist = _normalize_artist_for_search(artist_for_search) if artist_for_search else \"\"\n",
    "        sanitized_title = _normalize_title_for_search(title_for_search) if title_for_search else \"\"\n",
    "        sanitized_album = _normalize_title_for_search(album_for_search) if album_for_search else \"\"\n",
    "        logging.info(\"Search input (sanitized): artist='%s' | title='%s' | album='%s' | ext=%s\", sanitized_artist, sanitized_title, sanitized_album, ext)\n",
    "\n",
    "    match = None\n",
    "    # ISRC first\n",
    "    if isrc_tag:\n",
    "        isrc_q = f'isrc:\"{isrc_tag.strip()}\"'\n",
    "        if PRINT_SEARCH_INFO:\n",
    "            logging.info(\"Attempting ISRC search: %s\", isrc_q)\n",
    "        try:\n",
    "            j = spotifysearch(token, isrc_q, type_=\"track\", limit=1, offset=0, market=MARKET)\n",
    "            if j:\n",
    "                items = j.get(\"tracks\", {}).get(\"items\", [])\n",
    "                if items:\n",
    "                    match = items[0]\n",
    "        except Exception:\n",
    "            match = None\n",
    "\n",
    "    # containment search fallback\n",
    "    if not match:\n",
    "        match = spotify_find_best_match(token, artist_for_search, album_for_search, title_for_search, combined_limit=SEARCH_CANDIDATE_LIMIT)\n",
    "\n",
    "    if not match:\n",
    "        logging.info(\"No Spotify match for: %s\", file_path.name)\n",
    "        return False\n",
    "\n",
    "    # Extract fields from Spotify match\n",
    "    meta_artist = None\n",
    "    meta_title = None\n",
    "    meta_album = None\n",
    "    meta_date = None\n",
    "    meta_track = None\n",
    "    meta_disc = None\n",
    "    image_url = None\n",
    "    artist_id = None\n",
    "    genres_list: List[str] = []\n",
    "\n",
    "    if \"album\" in match and \"name\" in match:\n",
    "        meta_title = match.get(\"name\")\n",
    "        album_info = match.get(\"album\", {})\n",
    "        meta_album = album_info.get(\"name\")\n",
    "        artists = match.get(\"artists\", [])\n",
    "        if artists:\n",
    "            meta_artist = artists[0].get(\"name\")\n",
    "            artist_id = artists[0].get(\"id\")\n",
    "        meta_track = str(match.get(\"track_number\")) if match.get(\"track_number\") else None\n",
    "        meta_disc = str(match.get(\"disc_number\")) if match.get(\"disc_number\") else None\n",
    "        images = album_info.get(\"images\", [])\n",
    "        if images:\n",
    "            image_url = images[0].get(\"url\")\n",
    "        meta_date = album_info.get(\"release_date\")\n",
    "        if isinstance(album_info.get(\"genres\"), list) and album_info.get(\"genres\"):\n",
    "            genres_list = album_info.get(\"genres\", [])\n",
    "    else:\n",
    "        meta_album = match.get(\"name\")\n",
    "        artists = match.get(\"artists\", [])\n",
    "        if artists:\n",
    "            meta_artist = artists[0].get(\"name\")\n",
    "            artist_id = artists[0].get(\"id\")\n",
    "        images = match.get(\"images\", [])\n",
    "        if images:\n",
    "            image_url = images[0].get(\"url\")\n",
    "        meta_date = match.get(\"release_date\")\n",
    "        if isinstance(match.get(\"genres\"), list) and match.get(\"genres\"):\n",
    "            genres_list = match.get(\"genres\", [])\n",
    "\n",
    "    if PRINT_SEARCH_INFO:\n",
    "        candidate_album = None\n",
    "        if \"album\" in match:\n",
    "            candidate_album = (match.get(\"album\") or {}).get(\"name\")\n",
    "        else:\n",
    "            candidate_album = match.get(\"name\")\n",
    "        logging.info(\"Spotify candidate: spotify_title='%s' | spotify_artist='%s' | spotify_album='%s'\", meta_title, meta_artist, candidate_album)\n",
    "\n",
    "    # optionally fetch artist genres\n",
    "    if artist_id:\n",
    "        try:\n",
    "            g = get_artist_genres(token, artist_id)\n",
    "            if g:\n",
    "                genres_list = g\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if not genres_list and meta_artist:\n",
    "        try:\n",
    "            j = spotifysearch(token, f'artist:\"{meta_artist}\"', type_=\"artist\", limit=1, offset=0, market=MARKET)\n",
    "            if j:\n",
    "                items = j.get(\"artists\", {}).get(\"items\", [])\n",
    "                if items:\n",
    "                    gg = items[0].get(\"genres\", [])\n",
    "                    if isinstance(gg, list) and gg:\n",
    "                        genres_list = gg\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # metadata map\n",
    "    metadata_map = {\n",
    "        \"title\": meta_title or title or \"\",\n",
    "        \"artist\": meta_artist or artist or \"\",\n",
    "        \"album\": meta_album or album or \"\",\n",
    "        \"date\": meta_date or \"\",\n",
    "        \"track\": meta_track or \"\",\n",
    "        \"disc\": meta_disc or \"\",\n",
    "        \"genre\": \"; \".join(genres_list) if genres_list else \"\",\n",
    "        \"isrc\": isrc_tag or \"\"\n",
    "    }\n",
    "\n",
    "    temp_path = None\n",
    "    try:\n",
    "        temp_path = unique_temp_copy(file_path)\n",
    "\n",
    "        # FLAC\n",
    "        if ext == \".flac\":\n",
    "            audio_tmp = FLAC(str(temp_path))\n",
    "            if audio_tmp.tags is None:\n",
    "                audio_tmp.tags = {}\n",
    "            audio_tmp.tags[\"title\"] = [metadata_map[\"title\"]]\n",
    "            audio_tmp.tags[\"artist\"] = [metadata_map[\"artist\"]]\n",
    "            if metadata_map[\"album\"]:\n",
    "                audio_tmp.tags[\"album\"] = [metadata_map[\"album\"]]\n",
    "            if metadata_map[\"date\"]:\n",
    "                audio_tmp.tags[\"date\"] = [metadata_map[\"date\"]]\n",
    "            if metadata_map[\"track\"]:\n",
    "                audio_tmp.tags[\"tracknumber\"] = [metadata_map[\"track\"]]\n",
    "            if metadata_map[\"disc\"]:\n",
    "                audio_tmp.tags[\"discnumber\"] = [metadata_map[\"disc\"]]\n",
    "            if metadata_map[\"genre\"]:\n",
    "                audio_tmp.tags[\"genre\"] = [metadata_map[\"genre\"]]\n",
    "            if image_url:\n",
    "                got = download_image_bytes(image_url)\n",
    "                if got:\n",
    "                    image_bytes, mime = got\n",
    "                    pic = Picture()\n",
    "                    pic.data = image_bytes\n",
    "                    pic.type = 3\n",
    "                    pic.mime = mime\n",
    "                    try:\n",
    "                        # remove existing pictures to avoid duplication\n",
    "                        remove_existing_pictures_generic(file_path, audio_tmp)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    try:\n",
    "                        audio_tmp.add_picture(pic)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            try:\n",
    "                audio_tmp.save()\n",
    "            except Exception:\n",
    "                try:\n",
    "                    audio_tmp.save(str(temp_path))\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # MP3\n",
    "        elif ext == \".mp3\":\n",
    "            try:\n",
    "                audio_tmp = ID3(str(temp_path))\n",
    "            except ID3NoHeaderError:\n",
    "                audio_tmp = ID3()\n",
    "            audio_tmp.delall(\"TIT2\"); audio_tmp.add(TIT2(encoding=3, text=metadata_map[\"title\"]))\n",
    "            audio_tmp.delall(\"TPE1\"); audio_tmp.add(TPE1(encoding=3, text=metadata_map[\"artist\"]))\n",
    "            if metadata_map[\"album\"]:\n",
    "                audio_tmp.delall(\"TALB\"); audio_tmp.add(TALB(encoding=3, text=metadata_map[\"album\"]))\n",
    "            if metadata_map[\"date\"]:\n",
    "                audio_tmp.delall(\"TDRC\"); audio_tmp.add(TDRC(encoding=3, text=metadata_map[\"date\"]))\n",
    "            if metadata_map[\"track\"]:\n",
    "                audio_tmp.delall(\"TRCK\"); audio_tmp.add(TRCK(encoding=3, text=metadata_map[\"track\"]))\n",
    "            if metadata_map[\"disc\"]:\n",
    "                audio_tmp.delall(\"TPOS\"); audio_tmp.add(TPOS(encoding=3, text=metadata_map[\"disc\"]))\n",
    "            if metadata_map[\"genre\"]:\n",
    "                audio_tmp.delall(\"TCON\"); audio_tmp.add(TCON(encoding=3, text=metadata_map[\"genre\"]))\n",
    "            if metadata_map[\"isrc\"]:\n",
    "                try:\n",
    "                    audio_tmp.delall(\"TSRC\"); audio_tmp.add(TSRC(encoding=3, text=metadata_map[\"isrc\"]))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if image_url:\n",
    "                got = download_image_bytes(image_url)\n",
    "                if got:\n",
    "                    image_bytes, mime = got\n",
    "                    try:\n",
    "                        # remove existing APICs/pictures first\n",
    "                        remove_existing_pictures_generic(file_path, audio_tmp)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    try:\n",
    "                        audio_tmp.add(APIC(encoding=3, mime=mime, type=3, desc=\"Cover\", data=image_bytes))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            try:\n",
    "                audio_tmp.save(str(temp_path))\n",
    "            except Exception:\n",
    "                try:\n",
    "                    audio_tmp.save()\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # WAV\n",
    "        elif ext == \".wav\":\n",
    "            # Read original temp copy bytes\n",
    "            orig_bytes = Path(temp_path).read_bytes()\n",
    "\n",
    "            # detect ID3v2 header at very start (syncsafe size)\n",
    "            def parse_id3v2_header_size(head_bytes: bytes) -> int:\n",
    "                if len(head_bytes) < 10 or head_bytes[:3] != b\"ID3\":\n",
    "                    return 0\n",
    "                sz_bytes = head_bytes[6:10]\n",
    "                size = (sz_bytes[0] & 0x7F) << 21 | (sz_bytes[1] & 0x7F) << 14 | (sz_bytes[2] & 0x7F) << 7 | (sz_bytes[3] & 0x7F)\n",
    "                flags = head_bytes[5]\n",
    "                footer = 10 if (flags & 0x10) else 0\n",
    "                return 10 + size + footer\n",
    "\n",
    "            head = orig_bytes[:65536]\n",
    "            id3_head_size = parse_id3v2_header_size(head)\n",
    "            if id3_head_size > 0:\n",
    "                logging.info(\"WAV: detected ID3v2 header at start (size=%d). Skipping it for wave parsing.\", id3_head_size)\n",
    "                candidate_bytes = orig_bytes[id3_head_size:]\n",
    "            else:\n",
    "                riff_idx = head.find(b\"RIFF\")\n",
    "                if riff_idx > 0:\n",
    "                    logging.info(\"WAV: RIFF found at offset %d in header; using slice.\", riff_idx)\n",
    "                    candidate_bytes = orig_bytes[riff_idx:]\n",
    "                else:\n",
    "                    logging.info(\"WAV: no ID3 at start and no RIFF in first 64KB; using entire file as candidate.\")\n",
    "                    candidate_bytes = orig_bytes\n",
    "\n",
    "            # validate candidate contains RIFF\n",
    "            if candidate_bytes.find(b\"RIFF\") == -1:\n",
    "                logging.error(\"WAV candidate does not contain RIFF; aborting WAV write.\")\n",
    "                try:\n",
    "                    Path(temp_path).unlink()\n",
    "                except Exception:\n",
    "                    pass\n",
    "                return False\n",
    "\n",
    "            # Write candidate to tmp_in and re-build a clean WAV to ensure proper chunk layout\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_in:\n",
    "                tmp_in_name = tmp_in.name\n",
    "                tmp_in.write(candidate_bytes)\n",
    "            tmp_out_name = None\n",
    "            try:\n",
    "                with wave.open(tmp_in_name, 'rb') as r:\n",
    "                    params = r.getparams()\n",
    "                    frames = r.readframes(r.getnframes())\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_out:\n",
    "                    tmp_out_name = tmp_out.name\n",
    "                with wave.open(tmp_out_name, 'wb') as w:\n",
    "                    w.setparams(params)\n",
    "                    w.writeframes(frames)\n",
    "            except Exception as e:\n",
    "                logging.error(\"WAV rebuild failed: %s\", e)\n",
    "                try:\n",
    "                    Path(tmp_in_name).unlink(missing_ok=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                return False\n",
    "            finally:\n",
    "                try:\n",
    "                    Path(tmp_in_name).unlink(missing_ok=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Prepare LIST/INFO chunk and ID3 bytes\n",
    "            list_chunk = build_info_list_chunk(metadata_map)\n",
    "            image_bytes = None\n",
    "            image_mime = None\n",
    "            if image_url:\n",
    "                got = download_image_bytes(image_url)\n",
    "                if got:\n",
    "                    image_bytes, image_mime = got\n",
    "            id3_bytes = build_id3_bytes_for_wav(image_bytes, image_mime, metadata_map)\n",
    "\n",
    "            # Read the clean WAV we wrote\n",
    "            clean_bytes = Path(tmp_out_name).read_bytes()\n",
    "\n",
    "            # Strip any pre-existing id3 / LIST INFO chunks to avoid duplicates\n",
    "            try:\n",
    "                clean_bytes = strip_id3_and_list_info(clean_bytes)\n",
    "            except Exception as e:\n",
    "                logging.info(\"WAV: failed to strip existing id3/LIST chunks (non-fatal): %s\", e)\n",
    "\n",
    "            if list_chunk:\n",
    "                try:\n",
    "                    # list_chunk already contains its 'LIST' header + size; we pass only the \"INFO\"+subchunks as chunk_data\n",
    "                    clean_bytes = insert_chunk_before_data(clean_bytes, b\"LIST\", list_chunk[8:])  # pass only 'INFO'+subchunks as data\n",
    "                    logging.info(\"WAV: LIST/INFO chunk inserted.\")\n",
    "                except Exception as e:\n",
    "                    logging.info(\"WAV: failed to insert LIST chunk: %s\", e)\n",
    "            if id3_bytes:\n",
    "                try:\n",
    "                    clean_bytes = insert_chunk_before_data(clean_bytes, b\"id3 \", id3_bytes)\n",
    "                    logging.info(\"WAV: 'id3 ' chunk (ID3v2.3 with APIC + textual frames) inserted.\")\n",
    "                except Exception as e:\n",
    "                    logging.info(\"WAV: failed to insert id3 chunk: %s\", e)\n",
    "\n",
    "            # Overwrite temp_path with new bytes\n",
    "            try:\n",
    "                Path(temp_path).write_bytes(clean_bytes)\n",
    "            except Exception as e:\n",
    "                logging.error(\"Failed writing final WAV bytes to temp file: %s\", e)\n",
    "                try:\n",
    "                    Path(tmp_out_name).unlink(missing_ok=True)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                return False\n",
    "\n",
    "            try:\n",
    "                Path(tmp_out_name).unlink(missing_ok=True)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        else:\n",
    "            logging.info(\"Unsupported for write: %s\", file_path.name)\n",
    "            if temp_path and Path(temp_path).exists():\n",
    "                try:\n",
    "                    temp_path.unlink()\n",
    "                except Exception:\n",
    "                    pass\n",
    "            return False\n",
    "\n",
    "        # Replace original: send original to trash and move temp into place\n",
    "        send_original_to_trash(file_path)\n",
    "        shutil.move(str(temp_path), str(file_path))\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        if temp_path and Path(temp_path).exists():\n",
    "            try:\n",
    "                Path(temp_path).unlink()\n",
    "            except Exception:\n",
    "                pass\n",
    "        logging.error(\"Failed updating %s: %s\", file_path.name, e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8dde20",
   "metadata": {},
   "source": [
    "File iteration + MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# FILE ITERATION + MAIN\n",
    "# -------------------------\n",
    "def iter_audio_files(root: Path, recursive: bool):\n",
    "    patterns = (\"*.flac\", \"*.mp3\", \"*.wav\")\n",
    "    if recursive:\n",
    "        for pat in patterns:\n",
    "            yield from root.rglob(pat)\n",
    "    else:\n",
    "        for pat in patterns:\n",
    "            yield from root.glob(pat)\n",
    "\n",
    "\n",
    "def get_creation_time(path: Path) -> float:\n",
    "    try:\n",
    "        s = path.stat()\n",
    "        if hasattr(s, \"st_birthtime\"):\n",
    "            return float(s.st_birthtime)\n",
    "        if platform.system() == \"Windows\":\n",
    "            return float(s.st_ctime)\n",
    "        return float(s.st_mtime)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Load credentials (client id/secret) and music path from credentials.json\n",
    "    try:\n",
    "        with CREDENTIALS_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        client_id = str(data.get(\"client_id\", \"\")).strip()\n",
    "        client_secret = str(data.get(\"client_secret\", \"\")).strip()\n",
    "        music_path = data.get(\"music_path\") or data.get(\"source_dir\") or data.get(\"music_dir\")\n",
    "        if not client_id or not client_secret:\n",
    "            logging.error(\"Missing client_id or client_secret in credentials.json\")\n",
    "            return\n",
    "        if not music_path:\n",
    "            logging.error(\"Missing music_path in credentials.json\")\n",
    "            return\n",
    "        SOURCE_DIR = Path(music_path)\n",
    "        if not SOURCE_DIR.exists() or not SOURCE_DIR.is_dir():\n",
    "            logging.error(\"music_path from credentials.json is not a valid directory: %s\", SOURCE_DIR)\n",
    "            return\n",
    "        logging.info(\"Loaded music path from credentials.json: %s\", SOURCE_DIR)\n",
    "\n",
    "        token, expires_at = get_spotify_token(client_id, client_secret)\n",
    "        logging.info(\"Spotify token obtained\")\n",
    "    except Exception as e:\n",
    "        logging.error(\"Failed to load credentials or obtain token: %s\", e)\n",
    "        return\n",
    "\n",
    "    paths = [p for p in iter_audio_files(SOURCE_DIR, RECURSIVE)]\n",
    "    paths.sort(key=lambda p: get_creation_time(p) if p.exists() else 0, reverse=True)\n",
    "    total = len(paths)\n",
    "    logging.info(\"Found %d audio files (FLAC/MP3/WAV) in %s\", total, SOURCE_DIR)\n",
    "\n",
    "    if PROCESS_TOP_X and isinstance(PROCESS_TOP_X, int) and PROCESS_TOP_X > 0:\n",
    "        limit = min(PROCESS_TOP_X, total)\n",
    "        paths = paths[:limit]\n",
    "\n",
    "    updated = skipped = failed = 0\n",
    "    for i, path in enumerate(paths, 1):\n",
    "        try:\n",
    "            if int(time.time()) >= expires_at:\n",
    "                try:\n",
    "                    token, expires_at = get_spotify_token(client_id, client_secret)\n",
    "                except Exception:\n",
    "                    logging.error(\"Failed to refresh Spotify token\")\n",
    "                    break\n",
    "\n",
    "            logging.info(\"Processing (%d/%d): %s\", i, len(paths), path.name)\n",
    "            ok = overwrite_metadata_with_spotify(path, token)\n",
    "            if ok:\n",
    "                logging.info(\"Updated metadata for: %s (original moved to trash)\", path.name)\n",
    "                updated += 1\n",
    "            else:\n",
    "                skipped += 1\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except Exception as e:\n",
    "            logging.error(\"Unexpected error processing %s: %s\", path.name, e)\n",
    "            failed += 1\n",
    "\n",
    "    logging.info(\"Completed. Updated: %d, Skipped: %d, Failed: %d, Total found: %d\", updated, skipped, failed, total)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deemon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
